mkdir classes; javac -classpath /opt/hadoop-2.7.2/share/hadoop/common/*:/opt/hadoop-2.7.2/share/hadoop/yarn/lib/*:/opt/hadoop-2.7.2/share/hadoop/mapreduce/lib/*:/opt/hadoop-2.7.2/share/hadoop/mapreduce/*:./  -d classes src/*.java; jar cvf PageRank.jar classes;echo classes/*.class; hadoop jar PageRank.jar PageRank
Note: src/PageRank.java uses or overrides a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
added manifest
adding: classes/(in = 0) (out= 0)(stored 0%)
adding: classes/NodeRecordWriter.class(in = 2130) (out= 1150)(deflated 46%)
adding: classes/LeftoverReducer.class(in = 1871) (out= 850)(deflated 54%)
adding: classes/NodeInputFormat.class(in = 823) (out= 362)(deflated 56%)
adding: classes/Node.class(in = 2745) (out= 1478)(deflated 46%)
adding: classes/NodeOrDouble.class(in = 1471) (out= 802)(deflated 45%)
adding: classes/LeftoverMapper.class(in = 1129) (out= 463)(deflated 58%)
adding: classes/NodeOutputFormat.class(in = 1566) (out= 685)(deflated 56%)
adding: classes/PageRank$myCounter.class(in = 896) (out= 509)(deflated 43%)
adding: classes/PageRank.class(in = 4015) (out= 2074)(deflated 48%)
adding: classes/NodeRecordReader.class(in = 3117) (out= 1540)(deflated 50%)
adding: classes/TrustReducer.class(in = 1714) (out= 782)(deflated 54%)
adding: classes/TrustMapper.class(in = 2061) (out= 993)(deflated 51%)
classes/LeftoverMapper.class classes/LeftoverReducer.class classes/Node.class classes/NodeInputFormat.class classes/NodeOrDouble.class classes/NodeOutputFormat.class classes/NodeRecordReader.class classes/NodeRecordWriter.class classes/PageRank$myCounter.class classes/PageRank.class classes/TrustMapper.class classes/TrustReducer.class
Using input file input/center.txt
16/04/05 23:10:51 INFO Configuration.deprecation: session.id is deprecated. Instead, use dfs.metrics.session-id
16/04/05 23:10:51 INFO jvm.JvmMetrics: Initializing JVM Metrics with processName=JobTracker, sessionId=
16/04/05 23:10:52 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:52 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:52 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:52 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:52 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local421084643_0001
16/04/05 23:10:52 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:52 INFO mapreduce.Job: Running job: job_local421084643_0001
16/04/05 23:10:52 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:53 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Starting task: attempt_local421084643_0001_m_000000_0
16/04/05 23:10:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:53 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/input/center.txt:0+54
16/04/05 23:10:53 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:53 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:53 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:53 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:53 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:53 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:53 INFO mapred.LocalJobRunner: 
16/04/05 23:10:53 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:53 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:53 INFO mapred.MapTask: bufstart = 0; bufend = 224; bufvoid = 104857600
16/04/05 23:10:53 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
16/04/05 23:10:53 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:53 INFO mapred.Task: Task:attempt_local421084643_0001_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:53 INFO mapred.LocalJobRunner: map
16/04/05 23:10:53 INFO mapred.Task: Task 'attempt_local421084643_0001_m_000000_0' done.
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local421084643_0001_m_000000_0
16/04/05 23:10:53 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Starting task: attempt_local421084643_0001_r_000000_0
16/04/05 23:10:53 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:53 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:53 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@34ff4fb3
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:53 INFO reduce.EventFetcher: attempt_local421084643_0001_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:53 INFO reduce.LocalFetcher: localfetcher#1 about to shuffle output of map attempt_local421084643_0001_m_000000_0 decomp: 250 len: 254 to MEMORY
16/04/05 23:10:53 INFO reduce.InMemoryMapOutput: Read 250 bytes from map-output for attempt_local421084643_0001_m_000000_0
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->250
16/04/05 23:10:53 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:53 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:53 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: Merged 1 segments, 250 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: Merging 1 files, 254 bytes from disk
16/04/05 23:10:53 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:53 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:53 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:53 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:53 INFO Configuration.deprecation: mapred.skip.on is deprecated. Instead, use mapreduce.job.skiprecords

1 0.0 2,3,4 IN THIS PLACE 


2 0.041666666666666664 3,4 IN THIS PLACE 


3 0.3541666666666667 IN THIS PLACE 


4 0.10416666666666666 3 IN THIS PLACE 


5 0.0 3 IN THIS PLACE 

16/04/05 23:10:53 INFO mapred.Task: Task:attempt_local421084643_0001_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:53 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:53 INFO mapred.Task: Task 'attempt_local421084643_0001_r_000000_0' done.
16/04/05 23:10:53 INFO mapred.LocalJobRunner: Finishing task: attempt_local421084643_0001_r_000000_0
16/04/05 23:10:53 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:10:53 INFO mapreduce.Job: Job job_local421084643_0001 running in uber mode : false
16/04/05 23:10:54 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:10:54 INFO mapreduce.Job: Job job_local421084643_0001 completed successfully
16/04/05 23:10:54 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=1038
		FILE: Number of bytes written=572428
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=224
		Map output materialized bytes=254
		Input split bytes=141
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=254
		Reduce input records=12
		Reduce output records=5
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=273424384
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	myCounter
		COUNTER=12500000
		SIZE=5
	File Input Format Counters 
		Bytes Read=54
	File Output Format Counters 
		Bytes Written=104
leftover: 0
size: 0
16/04/05 23:10:54 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:10:54 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:54 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:54 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:54 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:54 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local468257438_0002
16/04/05 23:10:54 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:54 INFO mapreduce.Job: Running job: job_local468257438_0002
16/04/05 23:10:54 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:54 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Starting task: attempt_local468257438_0002_m_000000_0
16/04/05 23:10:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:54 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage0/output.txt:0+92
16/04/05 23:10:54 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:54 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:54 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:54 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:54 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:54 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:54 INFO mapred.LocalJobRunner: 
16/04/05 23:10:54 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:54 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:54 INFO mapred.MapTask: bufstart = 0; bufend = 128; bufvoid = 104857600
16/04/05 23:10:54 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
16/04/05 23:10:54 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:54 INFO mapred.Task: Task:attempt_local468257438_0002_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:54 INFO mapred.LocalJobRunner: map
16/04/05 23:10:54 INFO mapred.Task: Task 'attempt_local468257438_0002_m_000000_0' done.
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local468257438_0002_m_000000_0
16/04/05 23:10:54 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Starting task: attempt_local468257438_0002_r_000000_0
16/04/05 23:10:54 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:54 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:54 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@170287bf
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:54 INFO reduce.EventFetcher: attempt_local468257438_0002_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:54 INFO reduce.LocalFetcher: localfetcher#2 about to shuffle output of map attempt_local468257438_0002_m_000000_0 decomp: 140 len: 144 to MEMORY
16/04/05 23:10:54 INFO reduce.InMemoryMapOutput: Read 140 bytes from map-output for attempt_local468257438_0002_m_000000_0
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140
16/04/05 23:10:54 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:54 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:54 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:54 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:54 WARN io.ReadaheadPool: Failed readahead on ifile
EBADF: Bad file descriptor
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posix_fadvise(Native Method)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX.posixFadviseIfPossible(NativeIO.java:267)
	at org.apache.hadoop.io.nativeio.NativeIO$POSIX$CacheManipulator.posixFadviseIfPossible(NativeIO.java:146)
	at org.apache.hadoop.io.ReadaheadPool$ReadaheadRequestImpl.run(ReadaheadPool.java:206)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)
	at java.lang.Thread.run(Thread.java:745)
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: Merged 1 segments, 140 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
16/04/05 23:10:54 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:54 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:54 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:54 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 NaN 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 NaN 3 IN THIS PLACE 

16/04/05 23:10:54 INFO mapred.Task: Task:attempt_local468257438_0002_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:54 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:54 INFO mapred.Task: Task 'attempt_local468257438_0002_r_000000_0' done.
16/04/05 23:10:54 INFO mapred.LocalJobRunner: Finishing task: attempt_local468257438_0002_r_000000_0
16/04/05 23:10:54 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:10:55 INFO mapreduce.Job: Job job_local468257438_0002 running in uber mode : false
16/04/05 23:10:55 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:10:55 INFO mapreduce.Job: Job job_local468257438_0002 completed successfully
16/04/05 23:10:55 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=2506
		FILE: Number of bytes written=1144470
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=128
		Map output materialized bytes=144
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=144
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=367796224
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=108
	File Output Format Counters 
		Bytes Written=56
leftover: COUNTER
size: SIZE
16/04/05 23:10:55 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:10:55 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:55 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:55 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:55 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:55 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1733222094_0003
16/04/05 23:10:55 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:55 INFO mapreduce.Job: Running job: job_local1733222094_0003
16/04/05 23:10:55 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:55 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1733222094_0003_m_000000_0
16/04/05 23:10:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:55 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage1/output.txt:0+44
16/04/05 23:10:55 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:55 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:55 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:55 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:55 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:55 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:55 INFO mapred.LocalJobRunner: 
16/04/05 23:10:55 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:55 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:55 INFO mapred.MapTask: bufstart = 0; bufend = 224; bufvoid = 104857600
16/04/05 23:10:55 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
16/04/05 23:10:55 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:55 INFO mapred.Task: Task:attempt_local1733222094_0003_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:55 INFO mapred.LocalJobRunner: map
16/04/05 23:10:55 INFO mapred.Task: Task 'attempt_local1733222094_0003_m_000000_0' done.
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1733222094_0003_m_000000_0
16/04/05 23:10:55 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Starting task: attempt_local1733222094_0003_r_000000_0
16/04/05 23:10:55 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:55 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:55 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@71bd5cfa
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:55 INFO reduce.EventFetcher: attempt_local1733222094_0003_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:55 INFO reduce.LocalFetcher: localfetcher#3 about to shuffle output of map attempt_local1733222094_0003_m_000000_0 decomp: 250 len: 254 to MEMORY
16/04/05 23:10:55 INFO reduce.InMemoryMapOutput: Read 250 bytes from map-output for attempt_local1733222094_0003_m_000000_0
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->250
16/04/05 23:10:55 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:55 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:55 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: Merged 1 segments, 250 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: Merging 1 files, 254 bytes from disk
16/04/05 23:10:55 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:55 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:55 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:55 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 0.0 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 0.0 3 IN THIS PLACE 

16/04/05 23:10:55 INFO mapred.Task: Task:attempt_local1733222094_0003_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:55 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:55 INFO mapred.Task: Task 'attempt_local1733222094_0003_r_000000_0' done.
16/04/05 23:10:55 INFO mapred.LocalJobRunner: Finishing task: attempt_local1733222094_0003_r_000000_0
16/04/05 23:10:55 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:10:56 INFO mapreduce.Job: Job job_local1733222094_0003 running in uber mode : false
16/04/05 23:10:56 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:10:56 INFO mapreduce.Job: Job job_local1733222094_0003 completed successfully
16/04/05 23:10:56 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=3878
		FILE: Number of bytes written=1720032
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=224
		Map output materialized bytes=254
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=254
		Reduce input records=12
		Reduce output records=5
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=337387520
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	myCounter
		COUNTER=0
		SIZE=5
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: 0
size: 0
16/04/05 23:10:56 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:10:56 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:56 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:56 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:56 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:56 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1578599955_0004
16/04/05 23:10:56 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:56 INFO mapreduce.Job: Running job: job_local1578599955_0004
16/04/05 23:10:56 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:56 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1578599955_0004_m_000000_0
16/04/05 23:10:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:56 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage2/output.txt:0+44
16/04/05 23:10:56 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:56 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:56 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:56 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:56 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:56 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:56 INFO mapred.LocalJobRunner: 
16/04/05 23:10:56 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:56 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:56 INFO mapred.MapTask: bufstart = 0; bufend = 128; bufvoid = 104857600
16/04/05 23:10:56 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
16/04/05 23:10:56 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:56 INFO mapred.Task: Task:attempt_local1578599955_0004_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:56 INFO mapred.LocalJobRunner: map
16/04/05 23:10:56 INFO mapred.Task: Task 'attempt_local1578599955_0004_m_000000_0' done.
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1578599955_0004_m_000000_0
16/04/05 23:10:56 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Starting task: attempt_local1578599955_0004_r_000000_0
16/04/05 23:10:56 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:56 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:56 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@49761f9d
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:56 INFO reduce.EventFetcher: attempt_local1578599955_0004_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:56 INFO reduce.LocalFetcher: localfetcher#4 about to shuffle output of map attempt_local1578599955_0004_m_000000_0 decomp: 140 len: 144 to MEMORY
16/04/05 23:10:56 INFO reduce.InMemoryMapOutput: Read 140 bytes from map-output for attempt_local1578599955_0004_m_000000_0
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140
16/04/05 23:10:56 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:56 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:56 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:56 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: Merged 1 segments, 140 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
16/04/05 23:10:56 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:56 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:56 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:56 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 NaN 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 NaN 3 IN THIS PLACE 

16/04/05 23:10:56 INFO mapred.Task: Task:attempt_local1578599955_0004_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:56 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:56 INFO mapred.Task: Task 'attempt_local1578599955_0004_r_000000_0' done.
16/04/05 23:10:56 INFO mapred.LocalJobRunner: Finishing task: attempt_local1578599955_0004_r_000000_0
16/04/05 23:10:56 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:10:57 INFO mapreduce.Job: Job job_local1578599955_0004 running in uber mode : false
16/04/05 23:10:57 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:10:57 INFO mapreduce.Job: Job job_local1578599955_0004 completed successfully
16/04/05 23:10:57 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=5250
		FILE: Number of bytes written=2295030
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=128
		Map output materialized bytes=144
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=144
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=437534720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: COUNTER
size: SIZE
16/04/05 23:10:57 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:10:57 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:57 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:57 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:57 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:57 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1389834377_0005
16/04/05 23:10:57 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:57 INFO mapreduce.Job: Running job: job_local1389834377_0005
16/04/05 23:10:57 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:57 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:57 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:57 INFO mapred.LocalJobRunner: Starting task: attempt_local1389834377_0005_m_000000_0
16/04/05 23:10:57 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:57 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:57 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage3/output.txt:0+44
16/04/05 23:10:58 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:58 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:58 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:58 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:58 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:58 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:58 INFO mapred.LocalJobRunner: 
16/04/05 23:10:58 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:58 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:58 INFO mapred.MapTask: bufstart = 0; bufend = 224; bufvoid = 104857600
16/04/05 23:10:58 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
16/04/05 23:10:58 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:58 INFO mapred.Task: Task:attempt_local1389834377_0005_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:58 INFO mapred.LocalJobRunner: map
16/04/05 23:10:58 INFO mapred.Task: Task 'attempt_local1389834377_0005_m_000000_0' done.
16/04/05 23:10:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local1389834377_0005_m_000000_0
16/04/05 23:10:58 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:58 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:58 INFO mapred.LocalJobRunner: Starting task: attempt_local1389834377_0005_r_000000_0
16/04/05 23:10:58 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:58 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:58 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@2fbb7466
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:58 INFO reduce.EventFetcher: attempt_local1389834377_0005_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:58 INFO reduce.LocalFetcher: localfetcher#5 about to shuffle output of map attempt_local1389834377_0005_m_000000_0 decomp: 250 len: 254 to MEMORY
16/04/05 23:10:58 INFO reduce.InMemoryMapOutput: Read 250 bytes from map-output for attempt_local1389834377_0005_m_000000_0
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->250
16/04/05 23:10:58 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:58 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:58 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:58 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: Merged 1 segments, 250 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: Merging 1 files, 254 bytes from disk
16/04/05 23:10:58 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:58 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:58 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:10:58 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 0.0 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 0.0 3 IN THIS PLACE 

16/04/05 23:10:58 INFO mapred.Task: Task:attempt_local1389834377_0005_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:58 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:58 INFO mapred.Task: Task 'attempt_local1389834377_0005_r_000000_0' done.
16/04/05 23:10:58 INFO mapred.LocalJobRunner: Finishing task: attempt_local1389834377_0005_r_000000_0
16/04/05 23:10:58 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:10:58 INFO mapreduce.Job: Job job_local1389834377_0005 running in uber mode : false
16/04/05 23:10:58 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:10:58 INFO mapreduce.Job: Job job_local1389834377_0005 completed successfully
16/04/05 23:10:58 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=6622
		FILE: Number of bytes written=2870592
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=224
		Map output materialized bytes=254
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=254
		Reduce input records=12
		Reduce output records=5
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	myCounter
		COUNTER=0
		SIZE=5
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: 0
size: 0
16/04/05 23:10:58 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:10:58 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:10:58 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:10:59 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:10:59 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:10:59 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local262250226_0006
16/04/05 23:10:59 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:10:59 INFO mapreduce.Job: Running job: job_local262250226_0006
16/04/05 23:10:59 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:59 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Starting task: attempt_local262250226_0006_m_000000_0
16/04/05 23:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:59 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage4/output.txt:0+44
16/04/05 23:10:59 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:10:59 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:10:59 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:10:59 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:10:59 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:10:59 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:10:59 INFO mapred.LocalJobRunner: 
16/04/05 23:10:59 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:10:59 INFO mapred.MapTask: Spilling map output
16/04/05 23:10:59 INFO mapred.MapTask: bufstart = 0; bufend = 128; bufvoid = 104857600
16/04/05 23:10:59 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
16/04/05 23:10:59 INFO mapred.MapTask: Finished spill 0
16/04/05 23:10:59 INFO mapred.Task: Task:attempt_local262250226_0006_m_000000_0 is done. And is in the process of committing
16/04/05 23:10:59 INFO mapred.LocalJobRunner: map
16/04/05 23:10:59 INFO mapred.Task: Task 'attempt_local262250226_0006_m_000000_0' done.
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local262250226_0006_m_000000_0
16/04/05 23:10:59 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Starting task: attempt_local262250226_0006_r_000000_0
16/04/05 23:10:59 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:10:59 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:10:59 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@44a52b30
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:10:59 INFO reduce.EventFetcher: attempt_local262250226_0006_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:10:59 INFO reduce.LocalFetcher: localfetcher#6 about to shuffle output of map attempt_local262250226_0006_m_000000_0 decomp: 140 len: 144 to MEMORY
16/04/05 23:10:59 INFO reduce.InMemoryMapOutput: Read 140 bytes from map-output for attempt_local262250226_0006_m_000000_0
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140
16/04/05 23:10:59 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:10:59 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:10:59 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: Merged 1 segments, 140 bytes to disk to satisfy reduce memory limit
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
16/04/05 23:10:59 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:10:59 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:10:59 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:10:59 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 NaN 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 NaN 3 IN THIS PLACE 

16/04/05 23:10:59 INFO mapred.Task: Task:attempt_local262250226_0006_r_000000_0 is done. And is in the process of committing
16/04/05 23:10:59 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:10:59 INFO mapred.Task: Task 'attempt_local262250226_0006_r_000000_0' done.
16/04/05 23:10:59 INFO mapred.LocalJobRunner: Finishing task: attempt_local262250226_0006_r_000000_0
16/04/05 23:10:59 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:11:00 INFO mapreduce.Job: Job job_local262250226_0006 running in uber mode : false
16/04/05 23:11:00 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:11:00 INFO mapreduce.Job: Job job_local262250226_0006 completed successfully
16/04/05 23:11:00 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=7994
		FILE: Number of bytes written=3442586
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=128
		Map output materialized bytes=144
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=144
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: COUNTER
size: SIZE
16/04/05 23:11:00 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:11:00 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:11:00 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:11:00 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:11:00 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:11:00 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1881363321_0007
16/04/05 23:11:00 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:11:00 INFO mapreduce.Job: Running job: job_local1881363321_0007
16/04/05 23:11:00 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:11:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:00 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1881363321_0007_m_000000_0
16/04/05 23:11:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:00 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage5/output.txt:0+44
16/04/05 23:11:00 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:11:00 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:11:00 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:11:00 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:11:00 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:11:00 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:11:00 INFO mapred.LocalJobRunner: 
16/04/05 23:11:00 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:11:00 INFO mapred.MapTask: Spilling map output
16/04/05 23:11:00 INFO mapred.MapTask: bufstart = 0; bufend = 224; bufvoid = 104857600
16/04/05 23:11:00 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
16/04/05 23:11:00 INFO mapred.MapTask: Finished spill 0
16/04/05 23:11:00 INFO mapred.Task: Task:attempt_local1881363321_0007_m_000000_0 is done. And is in the process of committing
16/04/05 23:11:00 INFO mapred.LocalJobRunner: map
16/04/05 23:11:00 INFO mapred.Task: Task 'attempt_local1881363321_0007_m_000000_0' done.
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1881363321_0007_m_000000_0
16/04/05 23:11:00 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Starting task: attempt_local1881363321_0007_r_000000_0
16/04/05 23:11:00 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:00 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:00 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@7c93d88e
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:11:00 INFO reduce.EventFetcher: attempt_local1881363321_0007_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:11:00 INFO reduce.LocalFetcher: localfetcher#7 about to shuffle output of map attempt_local1881363321_0007_m_000000_0 decomp: 250 len: 254 to MEMORY
16/04/05 23:11:00 INFO reduce.InMemoryMapOutput: Read 250 bytes from map-output for attempt_local1881363321_0007_m_000000_0
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->250
16/04/05 23:11:00 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:11:00 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:11:00 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:00 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: Merged 1 segments, 250 bytes to disk to satisfy reduce memory limit
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: Merging 1 files, 254 bytes from disk
16/04/05 23:11:00 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:11:00 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:00 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:11:00 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 0.0 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 0.0 3 IN THIS PLACE 

16/04/05 23:11:00 INFO mapred.Task: Task:attempt_local1881363321_0007_r_000000_0 is done. And is in the process of committing
16/04/05 23:11:00 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:11:00 INFO mapred.Task: Task 'attempt_local1881363321_0007_r_000000_0' done.
16/04/05 23:11:00 INFO mapred.LocalJobRunner: Finishing task: attempt_local1881363321_0007_r_000000_0
16/04/05 23:11:00 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:11:01 INFO mapreduce.Job: Job job_local1881363321_0007 running in uber mode : false
16/04/05 23:11:01 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:11:01 INFO mapreduce.Job: Job job_local1881363321_0007 completed successfully
16/04/05 23:11:01 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=9366
		FILE: Number of bytes written=4018148
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=224
		Map output materialized bytes=254
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=254
		Reduce input records=12
		Reduce output records=5
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	myCounter
		COUNTER=0
		SIZE=5
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: 0
size: 0
16/04/05 23:11:01 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:11:01 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:11:01 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:11:01 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:11:01 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:11:01 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1418137036_0008
16/04/05 23:11:01 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:11:01 INFO mapreduce.Job: Running job: job_local1418137036_0008
16/04/05 23:11:01 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:11:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:01 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1418137036_0008_m_000000_0
16/04/05 23:11:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:01 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage6/output.txt:0+44
16/04/05 23:11:01 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:11:01 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:11:01 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:11:01 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:11:01 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:11:01 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:11:01 INFO mapred.LocalJobRunner: 
16/04/05 23:11:01 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:11:01 INFO mapred.MapTask: Spilling map output
16/04/05 23:11:01 INFO mapred.MapTask: bufstart = 0; bufend = 128; bufvoid = 104857600
16/04/05 23:11:01 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
16/04/05 23:11:01 INFO mapred.MapTask: Finished spill 0
16/04/05 23:11:01 INFO mapred.Task: Task:attempt_local1418137036_0008_m_000000_0 is done. And is in the process of committing
16/04/05 23:11:01 INFO mapred.LocalJobRunner: map
16/04/05 23:11:01 INFO mapred.Task: Task 'attempt_local1418137036_0008_m_000000_0' done.
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1418137036_0008_m_000000_0
16/04/05 23:11:01 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Starting task: attempt_local1418137036_0008_r_000000_0
16/04/05 23:11:01 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:01 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:01 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@59053014
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:11:01 INFO reduce.EventFetcher: attempt_local1418137036_0008_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:11:01 INFO reduce.LocalFetcher: localfetcher#8 about to shuffle output of map attempt_local1418137036_0008_m_000000_0 decomp: 140 len: 144 to MEMORY
16/04/05 23:11:01 INFO reduce.InMemoryMapOutput: Read 140 bytes from map-output for attempt_local1418137036_0008_m_000000_0
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140
16/04/05 23:11:01 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:11:01 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:11:01 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: Merged 1 segments, 140 bytes to disk to satisfy reduce memory limit
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
16/04/05 23:11:01 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:11:01 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:01 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:11:01 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 NaN 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 NaN 3 IN THIS PLACE 

16/04/05 23:11:01 INFO mapred.Task: Task:attempt_local1418137036_0008_r_000000_0 is done. And is in the process of committing
16/04/05 23:11:01 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:11:01 INFO mapred.Task: Task 'attempt_local1418137036_0008_r_000000_0' done.
16/04/05 23:11:01 INFO mapred.LocalJobRunner: Finishing task: attempt_local1418137036_0008_r_000000_0
16/04/05 23:11:01 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:11:02 INFO mapreduce.Job: Job job_local1418137036_0008 running in uber mode : false
16/04/05 23:11:02 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:11:02 INFO mapreduce.Job: Job job_local1418137036_0008 completed successfully
16/04/05 23:11:02 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=10738
		FILE: Number of bytes written=4593146
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=128
		Map output materialized bytes=144
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=144
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: COUNTER
size: SIZE
16/04/05 23:11:02 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:11:02 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:11:02 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:11:02 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:11:02 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:11:02 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local1954426693_0009
16/04/05 23:11:02 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:11:02 INFO mapreduce.Job: Running job: job_local1954426693_0009
16/04/05 23:11:02 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:11:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:02 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1954426693_0009_m_000000_0
16/04/05 23:11:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:02 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage7/output.txt:0+44
16/04/05 23:11:02 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:11:02 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:11:02 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:11:02 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:11:02 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:11:02 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:11:02 INFO mapred.LocalJobRunner: 
16/04/05 23:11:02 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:11:02 INFO mapred.MapTask: Spilling map output
16/04/05 23:11:02 INFO mapred.MapTask: bufstart = 0; bufend = 224; bufvoid = 104857600
16/04/05 23:11:02 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214352(104857408); length = 45/6553600
16/04/05 23:11:02 INFO mapred.MapTask: Finished spill 0
16/04/05 23:11:02 INFO mapred.Task: Task:attempt_local1954426693_0009_m_000000_0 is done. And is in the process of committing
16/04/05 23:11:02 INFO mapred.LocalJobRunner: map
16/04/05 23:11:02 INFO mapred.Task: Task 'attempt_local1954426693_0009_m_000000_0' done.
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1954426693_0009_m_000000_0
16/04/05 23:11:02 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Starting task: attempt_local1954426693_0009_r_000000_0
16/04/05 23:11:02 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:02 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:02 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@1477830c
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:11:02 INFO reduce.EventFetcher: attempt_local1954426693_0009_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:11:02 INFO reduce.LocalFetcher: localfetcher#9 about to shuffle output of map attempt_local1954426693_0009_m_000000_0 decomp: 250 len: 254 to MEMORY
16/04/05 23:11:02 INFO reduce.InMemoryMapOutput: Read 250 bytes from map-output for attempt_local1954426693_0009_m_000000_0
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 250, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->250
16/04/05 23:11:02 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:11:02 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:11:02 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: Merged 1 segments, 250 bytes to disk to satisfy reduce memory limit
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: Merging 1 files, 254 bytes from disk
16/04/05 23:11:02 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:11:02 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:02 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 244 bytes
16/04/05 23:11:02 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 0.0 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 0.0 3 IN THIS PLACE 

16/04/05 23:11:02 INFO mapred.Task: Task:attempt_local1954426693_0009_r_000000_0 is done. And is in the process of committing
16/04/05 23:11:02 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:11:02 INFO mapred.Task: Task 'attempt_local1954426693_0009_r_000000_0' done.
16/04/05 23:11:02 INFO mapred.LocalJobRunner: Finishing task: attempt_local1954426693_0009_r_000000_0
16/04/05 23:11:02 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:11:03 INFO mapreduce.Job: Job job_local1954426693_0009 running in uber mode : false
16/04/05 23:11:03 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:11:03 INFO mapreduce.Job: Job job_local1954426693_0009 completed successfully
16/04/05 23:11:03 INFO mapreduce.Job: Counters: 32
	File System Counters
		FILE: Number of bytes read=12110
		FILE: Number of bytes written=5168708
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=12
		Map output bytes=224
		Map output materialized bytes=254
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=254
		Reduce input records=12
		Reduce output records=5
		Spilled Records=24
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	myCounter
		COUNTER=0
		SIZE=5
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: 0
size: 0
16/04/05 23:11:03 INFO jvm.JvmMetrics: Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
16/04/05 23:11:03 WARN mapreduce.JobResourceUploader: Hadoop command-line option parsing not performed. Implement the Tool interface and execute your application with ToolRunner to remedy this.
16/04/05 23:11:03 WARN mapreduce.JobResourceUploader: No job jar file set.  User classes may not be found. See Job or Job#setJar(String).
16/04/05 23:11:03 INFO input.FileInputFormat: Total input paths to process : 1
16/04/05 23:11:03 INFO mapreduce.JobSubmitter: number of splits:1
16/04/05 23:11:03 INFO mapreduce.JobSubmitter: Submitting tokens for job: job_local2080285429_0010
16/04/05 23:11:03 INFO mapreduce.Job: The url to track the job: http://localhost:8080/
16/04/05 23:11:03 INFO mapreduce.Job: Running job: job_local2080285429_0010
16/04/05 23:11:03 INFO mapred.LocalJobRunner: OutputCommitter set in config null
16/04/05 23:11:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:03 INFO mapred.LocalJobRunner: OutputCommitter is org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Waiting for map tasks
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Starting task: attempt_local2080285429_0010_m_000000_0
16/04/05 23:11:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:03 INFO mapred.MapTask: Processing split: file:/home/richardo92/Desktop/CS5320-Database/hw04/skeleton/stage8/output.txt:0+44
16/04/05 23:11:03 INFO mapred.MapTask: (EQUATOR) 0 kvi 26214396(104857584)
16/04/05 23:11:03 INFO mapred.MapTask: mapreduce.task.io.sort.mb: 100
16/04/05 23:11:03 INFO mapred.MapTask: soft limit at 83886080
16/04/05 23:11:03 INFO mapred.MapTask: bufstart = 0; bufvoid = 104857600
16/04/05 23:11:03 INFO mapred.MapTask: kvstart = 26214396; length = 6553600
16/04/05 23:11:03 INFO mapred.MapTask: Map output collector class = org.apache.hadoop.mapred.MapTask$MapOutputBuffer
16/04/05 23:11:03 INFO mapred.LocalJobRunner: 
16/04/05 23:11:03 INFO mapred.MapTask: Starting flush of map output
16/04/05 23:11:03 INFO mapred.MapTask: Spilling map output
16/04/05 23:11:03 INFO mapred.MapTask: bufstart = 0; bufend = 128; bufvoid = 104857600
16/04/05 23:11:03 INFO mapred.MapTask: kvstart = 26214396(104857584); kvend = 26214380(104857520); length = 17/6553600
16/04/05 23:11:03 INFO mapred.MapTask: Finished spill 0
16/04/05 23:11:03 INFO mapred.Task: Task:attempt_local2080285429_0010_m_000000_0 is done. And is in the process of committing
16/04/05 23:11:03 INFO mapred.LocalJobRunner: map
16/04/05 23:11:03 INFO mapred.Task: Task 'attempt_local2080285429_0010_m_000000_0' done.
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local2080285429_0010_m_000000_0
16/04/05 23:11:03 INFO mapred.LocalJobRunner: map task executor complete.
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Waiting for reduce tasks
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Starting task: attempt_local2080285429_0010_r_000000_0
16/04/05 23:11:03 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 1
16/04/05 23:11:03 INFO mapred.Task:  Using ResourceCalculatorProcessTree : [ ]
16/04/05 23:11:03 INFO mapred.ReduceTask: Using ShuffleConsumerPlugin: org.apache.hadoop.mapreduce.task.reduce.Shuffle@3f9d5ab1
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: MergerManager: memoryLimit=363285696, maxSingleShuffleLimit=90821424, mergeThreshold=239768576, ioSortFactor=10, memToMemMergeOutputsThreshold=10
16/04/05 23:11:03 INFO reduce.EventFetcher: attempt_local2080285429_0010_r_000000_0 Thread started: EventFetcher for fetching Map Completion Events
16/04/05 23:11:03 INFO reduce.LocalFetcher: localfetcher#10 about to shuffle output of map attempt_local2080285429_0010_m_000000_0 decomp: 140 len: 144 to MEMORY
16/04/05 23:11:03 INFO reduce.InMemoryMapOutput: Read 140 bytes from map-output for attempt_local2080285429_0010_m_000000_0
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: closeInMemoryFile -> map-output of size: 140, inMemoryMapOutputs.size() -> 1, commitMemory -> 0, usedMemory ->140
16/04/05 23:11:03 INFO reduce.EventFetcher: EventFetcher is interrupted.. Returning
16/04/05 23:11:03 INFO mapred.LocalJobRunner: 1 / 1 copied.
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: finalMerge called with 1 in-memory map-outputs and 0 on-disk map-outputs
16/04/05 23:11:03 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: Merged 1 segments, 140 bytes to disk to satisfy reduce memory limit
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: Merging 1 files, 144 bytes from disk
16/04/05 23:11:03 INFO reduce.MergeManagerImpl: Merging 0 segments, 0 bytes from memory into reduce
16/04/05 23:11:03 INFO mapred.Merger: Merging 1 sorted segments
16/04/05 23:11:03 INFO mapred.Merger: Down to the last merge-pass, with 1 segments left of total size: 134 bytes
16/04/05 23:11:03 INFO mapred.LocalJobRunner: 1 / 1 copied.

1 NaN 2,3,4 IN THIS PLACE 


2 NaN 3,4 IN THIS PLACE 


3 NaN IN THIS PLACE 


4 NaN 3 IN THIS PLACE 


5 NaN 3 IN THIS PLACE 

16/04/05 23:11:03 INFO mapred.Task: Task:attempt_local2080285429_0010_r_000000_0 is done. And is in the process of committing
16/04/05 23:11:03 INFO mapred.LocalJobRunner: reduce > reduce
16/04/05 23:11:03 INFO mapred.Task: Task 'attempt_local2080285429_0010_r_000000_0' done.
16/04/05 23:11:03 INFO mapred.LocalJobRunner: Finishing task: attempt_local2080285429_0010_r_000000_0
16/04/05 23:11:03 INFO mapred.LocalJobRunner: reduce task executor complete.
16/04/05 23:11:04 INFO mapreduce.Job: Job job_local2080285429_0010 running in uber mode : false
16/04/05 23:11:04 INFO mapreduce.Job:  map 100% reduce 100%
16/04/05 23:11:04 INFO mapreduce.Job: Job job_local2080285429_0010 completed successfully
16/04/05 23:11:04 INFO mapreduce.Job: Counters: 30
	File System Counters
		FILE: Number of bytes read=13482
		FILE: Number of bytes written=5743706
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=5
		Map output bytes=128
		Map output materialized bytes=144
		Input split bytes=142
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=144
		Reduce input records=5
		Reduce output records=5
		Spilled Records=10
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=273432576
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=60
	File Output Format Counters 
		Bytes Written=56
leftover: COUNTER
size: SIZE
